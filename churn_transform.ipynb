{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "695271ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_data_info(churnDataFrame: pd.DataFrame) -> None:\n",
    "    print(f'Column Count: {len(churnDataFrame.columns)}')\n",
    "    print(f'Row Count: {len(churnDataFrame)}')\n",
    "    print(f'Data Columns: {list(churnDataFrame.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "2b22fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Error Rows\n",
    "\n",
    "def remove_errors(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    rowCount = len(churnDataFrame)\n",
    "    errorCounts = len(churnDataFrame[churnDataFrame['avg_frequency_login_days'] == 'Error'])\n",
    "    churnDataFrame = churnDataFrame[churnDataFrame['avg_frequency_login_days'] != 'Error']\n",
    "    print(f'{errorCounts} Errors Rows Removed out of {rowCount}')\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "20702181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate removal function\n",
    "\n",
    "def remove_duplicates(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    originalSize = len(churnDataFrame)\n",
    "    churnDataFrame = churnDataFrame.drop_duplicates(subset='security_no', keep='first')\n",
    "    NewSize = len(churnDataFrame)\n",
    "    numDuplicates = originalSize - NewSize\n",
    "    print(f\"Number of duplicates removed: {numDuplicates}\")\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "1ae289bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn and Non Churn Distribution\n",
    "\n",
    "def churn_distrubtion(churnDataFrame: pd.DataFrame) -> None:\n",
    "    print((churnDataFrame['churn_risk_score'].value_counts(\n",
    "        normalize=True) * 100).round(2).to_frame().T.rename(columns={1:'Percenrage At Risk',0:'Percentage Not At Risk'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "92509174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_transform(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    intColsTransform = ['days_since_last_login','age','avg_frequency_login_days']\n",
    "    floatColsTransform = ['avg_time_spent','avg_transaction_value','points_in_wallet']\n",
    "\n",
    "    for col in intColsTransform:\n",
    "        print(f'Processing Integer values in \"{col}\"...')\n",
    "        churnDataFrame[col] = abs(pd.to_numeric(churnDataFrame[col], errors='coerce')).round(0).astype('Int64')\n",
    "        Q1 = churnDataFrame[col].quantile(0.10)\n",
    "        Q3 = churnDataFrame[col].quantile(0.90)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 4 * IQR\n",
    "        upper_bound = Q3 + 4 * IQR\n",
    "        far_outliers = churnDataFrame[col][(churnDataFrame[col] < lower_bound) | (churnDataFrame[col] > upper_bound)]\n",
    "        if far_outliers.empty:\n",
    "            print(f'No far outliers found in {col}...')\n",
    "        else:\n",
    "            print(f'{len(far_outliers)} far outliers found in {col}: {sorted(set(far_outliers))}...')\n",
    "            medianVal = churnDataFrame[col].loc[~churnDataFrame.index.isin(far_outliers.index)].median()\n",
    "            churnDataFrame.loc[churnDataFrame.index.isin(far_outliers.index), col] = medianVal\n",
    "            print(f'The median valuse of {medianVal} imputed for all outliers')\n",
    "\n",
    "    print(\"-------------------\")\n",
    "\n",
    "    for col in floatColsTransform:\n",
    "        print(f'Processing float values in \"{col}\"...')\n",
    "        churnDataFrame[col] = abs(pd.to_numeric(churnDataFrame[col], errors='coerce')).round(2).astype('float64')\n",
    "        Q1 = churnDataFrame[col].quantile(0.10)\n",
    "        Q3 = churnDataFrame[col].quantile(0.90)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 4 * IQR\n",
    "        upper_bound = Q3 + 4 * IQR\n",
    "        far_outliers = churnDataFrame[col][(churnDataFrame[col] < lower_bound) | (churnDataFrame[col] > upper_bound)]\n",
    "        if far_outliers.empty:\n",
    "            print(f'No far outliers found in {col}...')\n",
    "        else:\n",
    "            print(f'{len(far_outliers)} far outliers found in {col}: {sorted(set(far_outliers))}...')\n",
    "            medianVal = churnDataFrame[col].loc[~churnDataFrame.index.isin(far_outliers.index)].median()\n",
    "            churnDataFrame.loc[churnDataFrame.index.isin(far_outliers.index), col] = medianVal\n",
    "            print(f'The median valuse of {medianVal} imputed for all outliers')\n",
    "\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "024eaa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nulls(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    missingDataCols = list(churnDataFrame.isna().sum()[churnDataFrame.isna().sum() > 0].to_frame().T.columns)\n",
    "    for col in missingDataCols:\n",
    "        print(f\"{col} contains: {churnDataFrame[col].isna().sum()} null values\")\n",
    "\n",
    "    # Isolate a list of columns that are numeric and string based that contain missing values using list comprehensions\n",
    "    boolCols = ['used_special_discount','offer_application_preference', 'past_complaint']\n",
    "    stringCols = [col for col in list(churnDataFrame.select_dtypes(include='object').columns) if col in missingDataCols and col not in boolCols]\n",
    "    numericCols = [col for col in list(churnDataFrame.select_dtypes(include=['int64','float64']).columns) if col in missingDataCols]\n",
    "\n",
    "    # Loop over string and numeric cols and perform low level imputation\n",
    "    for col in stringCols:\n",
    "        churnDataFrame[col] = churnDataFrame[col].apply(lambda row: 'Unknown' if pd.isnull(row) else row)\n",
    "    for col in numericCols:\n",
    "        churnDataFrame[col] = (churnDataFrame[col].apply(lambda row: 0 if pd.isnull(row) else row)).round(2)\n",
    "    for col in boolCols:\n",
    "        churnDataFrame[col] = churnDataFrame[col].apply(lambda row: 'No' if pd.isnull(row) else row)\n",
    "    print('Null records processed...')\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "24138db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_transformation(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'joining_date' in churnDataFrame.columns:\n",
    "        churnDataFrame['joining_date'] = pd.to_datetime(churnDataFrame['joining_date'])\n",
    "        churnDataFrame['join_year'] = churnDataFrame['joining_date'].dt.year.astype('Int64')\n",
    "        churnDataFrame['join_month'] = churnDataFrame['joining_date'].dt.month.astype('Int64')\n",
    "        churnDataFrame['join_day'] = churnDataFrame['joining_date'].dt.day.astype('Int64')\n",
    "        churnDataFrame = churnDataFrame.drop(columns=['joining_date'])\n",
    "        print('joining_date field transformed...')\n",
    "        return churnDataFrame\n",
    "    else:\n",
    "        print('join_date field not in data...')\n",
    "        return churnDataFrame\n",
    "\n",
    "def time_transformation(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'last_visit_time' in churnDataFrame.columns:\n",
    "        churnDataFrame['last_visit_time'] = pd.to_datetime(churnDataFrame['last_visit_time'], format='%H:%M:%S')\n",
    "        churnDataFrame['last_visit_hour'] = churnDataFrame['last_visit_time'].dt.hour.astype('Int64')\n",
    "        churnDataFrame['last_visit_min'] = churnDataFrame['last_visit_time'].dt.minute.astype('Int64')\n",
    "        churnDataFrame['last_visit_sec'] = churnDataFrame['last_visit_time'].dt.second.astype('Int64')\n",
    "        churnDataFrame = churnDataFrame.drop(columns=['last_visit_time'])\n",
    "        print('last_visit_time field transformed...')\n",
    "        return churnDataFrame\n",
    "    else:\n",
    "        print('last_visit_time field not in data...')\n",
    "        return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "28c1adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_characters(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    specialChars = r'[!?#]'\n",
    "    cols_with_special = [\n",
    "        col for col in churnDataFrame.columns\n",
    "        if churnDataFrame[col].astype(str).str.contains(specialChars, regex=True).any()]\n",
    "    print(f'Columns containing special character values: {cols_with_special}')\n",
    "\n",
    "    for col in cols_with_special:\n",
    "        uniqueVals = list(set(churnDataFrame[col].to_list()))\n",
    "        SpecialCharCount = churnDataFrame[col].str.count(specialChars).sum()\n",
    "        if col == 'joined_through_referral':\n",
    "            churnDataFrame[col] = churnDataFrame.apply(\n",
    "                lambda row: 'No' if row['referral_id'] in ['xxxxxxxx'] and row['joined_through_referral'] in uniqueVals else 'Yes',\n",
    "                axis=1)\n",
    "        else:\n",
    "            churnDataFrame[col] = churnDataFrame[col].apply(lambda row: 'Unknown' if row in specialChars else row)\n",
    "        print(f'Processed {SpecialCharCount} records of special charcters in \"{col}\" column.....')\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "8ccc9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_transform(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    feedBackMapping = {'Products always in Stock':1,\n",
    "    'User Friendly Website':1,\n",
    "    'Poor Customer Service':0,\n",
    "    'Poor Product Quality':0,\n",
    "    'Reasonable Price':1,\n",
    "    'Quality Customer Care':1,\n",
    "    'Too many ads':0,\n",
    "    'Poor Website':0,\n",
    "    'No reason specified':3}\n",
    "    for k,v in feedBackMapping.items():\n",
    "        print(f'Apply the following mapping: {k} : {v}')\n",
    "\n",
    "    churnDataFrame['feedback'] = churnDataFrame['feedback'].str.strip()\n",
    "    churnDataFrame['feedback'] = churnDataFrame['feedback'].apply(lambda row: feedBackMapping[row] if row in feedBackMapping else row)\n",
    "    churnDataFrame['feedback'] = churnDataFrame['feedback'].astype('Int64')\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "27ca5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    categoricalCols = list(churnDataFrame.select_dtypes(include='object').columns)\n",
    "    for col in categoricalCols:\n",
    "        print(f'Label Encoding values in {col}...')\n",
    "        print(f'Unique values in {col}:{list(set(churnDataFrame[col]))}')\n",
    "        labelEncoder = preprocessing.LabelEncoder()\n",
    "        churnDataFrame[col] = labelEncoder.fit_transform(churnDataFrame[col])\n",
    "        print(f'Categorical values mapped in {col} to integer values: {list(set(churnDataFrame[col]))}')\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "9df20aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(churnDataFrame: pd.DataFrame) -> pd.DataFrame:\n",
    "    churnDataFrame = churnDataFrame.drop(columns=['security_no','referral_id'])\n",
    "    print('Removed \"security_no\" and \"referral_id\" columns.....')\n",
    "    return churnDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "042b8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_transform_pipeline(rawFileName):\n",
    "\n",
    "    data = pd.read_csv(rawFileName)\n",
    "    print('Executing Transformation Pipeline...', end='\\n')\n",
    "    print()\n",
    "\n",
    "    print(\"----- Raw Churn Meta Data -----\",end='\\n')\n",
    "    meta_data_info(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Removing Errenous Rows -----\",end='\\n')\n",
    "    data = remove_errors(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Removing Duplicate Rows -----\",end='\\n')\n",
    "    data = remove_duplicates(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Distribution (%) of Customers at risk of Churn -----\",end='\\n')\n",
    "    churn_distrubtion(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Transform Numeric Values -----\",end='\\n')\n",
    "    data = numeric_transform(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Impute Values for Null Records -----\",end='\\n')\n",
    "    data = process_nulls(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Transform Date and Time Fields -----\",end='\\n')\n",
    "    data = date_transformation(data)\n",
    "    data = time_transformation(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Impute Values for Special Characters -----\",end='\\n')\n",
    "    data = special_characters(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Transform Feedback Column -----\",end='\\n')\n",
    "    data = feedback_transform(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Removing Unnecessary Features -----\",end='\\n')\n",
    "    data = remove_features(data)\n",
    "    print()\n",
    "\n",
    "    print(\"----- Encode Categorical Variables -----\",end='\\n')\n",
    "    data = label_encode(data)\n",
    "    print()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "3afdf742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Transformation Pipeline...\n",
      "\n",
      "----- Raw Churn Meta Data -----\n",
      "Column Count: 23\n",
      "Row Count: 36992\n",
      "Data Columns: ['age', 'gender', 'security_no', 'region_category', 'membership_category', 'joining_date', 'joined_through_referral', 'referral_id', 'preferred_offer_types', 'medium_of_operation', 'internet_option', 'last_visit_time', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet', 'used_special_discount', 'offer_application_preference', 'past_complaint', 'complaint_status', 'feedback', 'churn_risk_score']\n",
      "\n",
      "----- Removing Errenous Rows -----\n",
      "3522 Errors Rows Removed out of 36992\n",
      "\n",
      "----- Removing Duplicate Rows -----\n",
      "Number of duplicates removed: 0\n",
      "\n",
      "----- Distribution (%) of Customers at risk of Churn -----\n",
      "churn_risk_score  Percenrage At Risk  Percentage Not At Risk\n",
      "proportion                     54.07                   45.93\n",
      "\n",
      "----- Transform Numeric Values -----\n",
      "Processing Integer values in \"days_since_last_login\"...\n",
      "1817 far outliers found in days_since_last_login: [999]...\n",
      "The median valuse of 13.0 imputed for all outliers\n",
      "Processing Integer values in \"age\"...\n",
      "No far outliers found in age...\n",
      "Processing Integer values in \"avg_frequency_login_days\"...\n",
      "No far outliers found in avg_frequency_login_days...\n",
      "-------------------\n",
      "Processing float values in \"avg_time_spent\"...\n",
      "No far outliers found in avg_time_spent...\n",
      "Processing float values in \"avg_transaction_value\"...\n",
      "No far outliers found in avg_transaction_value...\n",
      "Processing float values in \"points_in_wallet\"...\n",
      "No far outliers found in points_in_wallet...\n",
      "\n",
      "----- Impute Values for Null Records -----\n",
      "region_category contains: 4906 null values\n",
      "preferred_offer_types contains: 262 null values\n",
      "points_in_wallet contains: 3118 null values\n",
      "Null records processed...\n",
      "\n",
      "----- Transform Date and Time Fields -----\n",
      "joining_date field transformed...\n",
      "last_visit_time field transformed...\n",
      "\n",
      "----- Impute Values for Special Characters -----\n",
      "Columns containing special character values: ['joined_through_referral', 'medium_of_operation']\n",
      "Processed 4924 records of special charcters in \"joined_through_referral\" column.....\n",
      "Processed 4859 records of special charcters in \"medium_of_operation\" column.....\n",
      "\n",
      "----- Transform Feedback Column -----\n",
      "Apply the following mapping: Products always in Stock : 1\n",
      "Apply the following mapping: User Friendly Website : 1\n",
      "Apply the following mapping: Poor Customer Service : 0\n",
      "Apply the following mapping: Poor Product Quality : 0\n",
      "Apply the following mapping: Reasonable Price : 1\n",
      "Apply the following mapping: Quality Customer Care : 1\n",
      "Apply the following mapping: Too many ads : 0\n",
      "Apply the following mapping: Poor Website : 0\n",
      "Apply the following mapping: No reason specified : 3\n",
      "\n",
      "----- Removing Unnecessary Features -----\n",
      "Removed \"security_no\" and \"referral_id\" columns.....\n",
      "\n",
      "----- Encode Categorical Variables -----\n",
      "Label Encoding values in gender...\n",
      "Unique values in gender:['M', 'F', 'Unknown']\n",
      "Categorical values mapped in gender to integer values: [0, 1, 2]\n",
      "Label Encoding values in region_category...\n",
      "Unique values in region_category:['Unknown', 'Town', 'City', 'Village']\n",
      "Categorical values mapped in region_category to integer values: [0, 1, 2, 3]\n",
      "Label Encoding values in membership_category...\n",
      "Unique values in membership_category:['Platinum Membership', 'No Membership', 'Gold Membership', 'Premium Membership', 'Basic Membership', 'Silver Membership']\n",
      "Categorical values mapped in membership_category to integer values: [0, 1, 2, 3, 4, 5]\n",
      "Label Encoding values in joined_through_referral...\n",
      "Unique values in joined_through_referral:['Yes', 'No']\n",
      "Categorical values mapped in joined_through_referral to integer values: [0, 1]\n",
      "Label Encoding values in preferred_offer_types...\n",
      "Unique values in preferred_offer_types:['Without Offers', 'Unknown', 'Credit/Debit Card Offers', 'Gift Vouchers/Coupons']\n",
      "Categorical values mapped in preferred_offer_types to integer values: [0, 1, 2, 3]\n",
      "Label Encoding values in medium_of_operation...\n",
      "Unique values in medium_of_operation:['Smartphone', 'Both', 'Unknown', 'Desktop']\n",
      "Categorical values mapped in medium_of_operation to integer values: [0, 1, 2, 3]\n",
      "Label Encoding values in internet_option...\n",
      "Unique values in internet_option:['Fiber_Optic', 'Mobile_Data', 'Wi-Fi']\n",
      "Categorical values mapped in internet_option to integer values: [0, 1, 2]\n",
      "Label Encoding values in used_special_discount...\n",
      "Unique values in used_special_discount:['Yes', 'No']\n",
      "Categorical values mapped in used_special_discount to integer values: [0, 1]\n",
      "Label Encoding values in offer_application_preference...\n",
      "Unique values in offer_application_preference:['Yes', 'No']\n",
      "Categorical values mapped in offer_application_preference to integer values: [0, 1]\n",
      "Label Encoding values in past_complaint...\n",
      "Unique values in past_complaint:['Yes', 'No']\n",
      "Categorical values mapped in past_complaint to integer values: [0, 1]\n",
      "Label Encoding values in complaint_status...\n",
      "Unique values in complaint_status:['Not Applicable', 'Solved', 'No Information Available', 'Solved in Follow-up', 'Unsolved']\n",
      "Categorical values mapped in complaint_status to integer values: [0, 1, 2, 3, 4]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>region_category</th>\n",
       "      <th>membership_category</th>\n",
       "      <th>joined_through_referral</th>\n",
       "      <th>preferred_offer_types</th>\n",
       "      <th>medium_of_operation</th>\n",
       "      <th>internet_option</th>\n",
       "      <th>days_since_last_login</th>\n",
       "      <th>avg_time_spent</th>\n",
       "      <th>...</th>\n",
       "      <th>past_complaint</th>\n",
       "      <th>complaint_status</th>\n",
       "      <th>feedback</th>\n",
       "      <th>churn_risk_score</th>\n",
       "      <th>join_year</th>\n",
       "      <th>join_month</th>\n",
       "      <th>join_day</th>\n",
       "      <th>last_visit_hour</th>\n",
       "      <th>last_visit_min</th>\n",
       "      <th>last_visit_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>300.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>306.34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>516.16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>53.27</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>113.13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36985</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>418.38</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36986</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>135.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36987</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>650.68</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36988</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>638.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36990</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>482.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33470 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  region_category  membership_category  \\\n",
       "0       18       0                3                    3   \n",
       "1       32       0                0                    4   \n",
       "2       44       0                1                    2   \n",
       "3       37       1                0                    2   \n",
       "4       31       0                0                    2   \n",
       "...    ...     ...              ...                  ...   \n",
       "36985   12       0                3                    4   \n",
       "36986   27       1                1                    3   \n",
       "36987   46       0                2                    0   \n",
       "36988   29       0                1                    0   \n",
       "36990   53       1                3                    3   \n",
       "\n",
       "       joined_through_referral  preferred_offer_types  medium_of_operation  \\\n",
       "0                            0                      1                    3   \n",
       "1                            1                      1                    1   \n",
       "2                            1                      1                    1   \n",
       "3                            1                      1                    1   \n",
       "4                            0                      0                    2   \n",
       "...                        ...                    ...                  ...   \n",
       "36985                        0                      1                    1   \n",
       "36986                        1                      0                    1   \n",
       "36987                        0                      0                    1   \n",
       "36988                        0                      3                    2   \n",
       "36990                        0                      1                    2   \n",
       "\n",
       "       internet_option  days_since_last_login  avg_time_spent  ...  \\\n",
       "0                    2                     17          300.63  ...   \n",
       "1                    1                     16          306.34  ...   \n",
       "2                    2                     14          516.16  ...   \n",
       "3                    1                     11           53.27  ...   \n",
       "4                    1                     20          113.13  ...   \n",
       "...                ...                    ...             ...  ...   \n",
       "36985                0                     13          418.38  ...   \n",
       "36986                1                     13          135.83  ...   \n",
       "36987                2                      2          650.68  ...   \n",
       "36988                2                     13          638.12  ...   \n",
       "36990                1                     15          482.61  ...   \n",
       "\n",
       "       past_complaint  complaint_status  feedback  churn_risk_score  \\\n",
       "0                   0                 1         1                 0   \n",
       "1                   1                 2         1                 0   \n",
       "2                   1                 3         0                 1   \n",
       "3                   1                 4         0                 1   \n",
       "4                   1                 2         0                 1   \n",
       "...               ...               ...       ...               ...   \n",
       "36985               1                 4         1                 0   \n",
       "36986               0                 1         3                 0   \n",
       "36987               1                 0         3                 1   \n",
       "36988               0                 1         0                 1   \n",
       "36990               0                 1         3                 0   \n",
       "\n",
       "       join_year  join_month  join_day  last_visit_hour  last_visit_min  \\\n",
       "0           2017           8        17               16               8   \n",
       "1           2017           8        28               12              38   \n",
       "2           2016          11        11               22              53   \n",
       "3           2016          10        29               15              57   \n",
       "4           2017           9        12               15              46   \n",
       "...          ...         ...       ...              ...             ...   \n",
       "36985       2016          10        25                3              30   \n",
       "36986       2015           9         7                5              29   \n",
       "36987       2017           9        21                4              14   \n",
       "36988       2016           6        27               23              18   \n",
       "36990       2017           6        15                9              50   \n",
       "\n",
       "       last_visit_sec  \n",
       "0                   2  \n",
       "1                  13  \n",
       "2                  21  \n",
       "3                  50  \n",
       "4                  44  \n",
       "...               ...  \n",
       "36985              17  \n",
       "36986              19  \n",
       "36987               5  \n",
       "36988              31  \n",
       "36990               3  \n",
       "\n",
       "[33470 rows x 25 columns]"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvFiles = [str(file) for file in Path('.').glob('*.csv')]\n",
    "for fileName in csvFiles:\n",
    "    churn_clean = execute_transform_pipeline(fileName)\n",
    "churn_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa74b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
