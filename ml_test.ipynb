{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "4bf9fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==1.7.6 in /opt/conda/lib/python3.10/site-packages (1.7.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost==1.7.6) (1.26.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost==1.7.6) (1.11.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==1.7.6\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import col, abs\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel, ClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import lit\n",
    "from pathlib import Path\n",
    "from pyspark import StorageLevel\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "import uuid\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "0ab2b5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.sql.shuffle.partitions -> 24\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ChurnXGBoost\").master(\"local[*]\").getOrCreate()\n",
    "cores = spark.sparkContext.defaultParallelism \n",
    "target_shuffle_partitions = cores * 2 # set custom partitions for shuffling based on available cores\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", target_shuffle_partitions) # will use above coun during shuffle operations\n",
    "print(\"spark.sql.shuffle.partitions ->\", spark.conf.get(\"spark.sql.shuffle.partitions\")) # displays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "fdd34240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_clean_churn_files() -> DataFrame | None:\n",
    "    \"\"\"\n",
    "    Combines all 'churn_clean*.csv' files in the current directory into a single Spark DataFrame.\n",
    "    The first matching file determines the schema. All subsequent files are appended.\n",
    "    If no matching files are found, the function returns None.\n",
    "    Returns:\n",
    "        churnCombinedDf: Spark DataFrame containing the combined data, or None if no files are found.\n",
    "    \"\"\"\n",
    "    csvFiles = [str(file) for file in Path(\".\").glob(\"churn_clean*.csv\")]\n",
    "    print(f\"All available cleaned churn csv files: {csvFiles}\")\n",
    "\n",
    "    if not csvFiles:\n",
    "        print(\"No churn_cleaned CSV files found...\")\n",
    "        return None\n",
    "    count = 0\n",
    "    for fileName in csvFiles:\n",
    "        if count == 0:\n",
    "            churnCombinedDf = spark.read.csv(fileName, header=True, inferSchema=True)\n",
    "            count += 1\n",
    "        else:\n",
    "            newChurnDf = spark.read.csv(fileName, header=True, inferSchema=True)\n",
    "            churnCombinedDf = churnCombinedDf.unionByName(newChurnDf)\n",
    "    return churnCombinedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "254013f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_churn_metadata(churnDataFrame: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Displays basic metadata about the churn DataFrame, including data types and non-null counts.\n",
    "    Converts the Spark DataFrame to a Pandas DataFrame for cleaner output.\n",
    "    Args:\n",
    "        churnDataFrame: Spark DataFrame containing the churn dataset.\n",
    "    Returns:\n",
    "        None. Prints metadata to the console.\n",
    "    \"\"\"\n",
    "    tempPandasDf = churnDataFrame.toPandas() \n",
    "    tempPandasDf.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "319b2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_by_label(churnDataFrame: DataFrame) -> tuple[DataFrame, DataFrame, bool]:\n",
    "    \"\"\"\n",
    "    Splits DataFrame into labeled and unlabeled sets based on if churn_risk_score contains empty rows.\n",
    "    If no unlabeled data exists, reserves 1% of labeled data for demonstrative prediction purposes.\n",
    "    Args:\n",
    "        churnDataFrame: Input DataFrame containing cleaned churn data.\n",
    "    Returns:\n",
    "        churnlabeled: Rows with churn_risk_score.\n",
    "        churnunlabeled: Rows without churn_risk_score or reserved data.\n",
    "        reservedFlag: Boolean True if data was reserved.\n",
    "    \"\"\"\n",
    "    churnlabeled = churnDataFrame.filter(col('churn_risk_score').isNotNull())\n",
    "    churnunlabeled = churnDataFrame.filter(col('churn_risk_score').isNull())\n",
    "    reserve = 0.01\n",
    "    reservedFlag = False\n",
    "    if churnunlabeled.count() == 0:\n",
    "        reservedFlag = True\n",
    "        print('no empty churn_risk_score rows...')\n",
    "        print(f\"Reserving {int(1)}% of labeled data for demo predictions...\")\n",
    "        trainDf, reservedDf = churnlabeled.randomSplit([1 - reserve, reserve], seed=42)\n",
    "        churnlabeled = trainDf\n",
    "        churnunlabeled = reservedDf\n",
    "        print(f\"Reserve dataframe with {churnunlabeled.count()} rows\")\n",
    "        churnunlabeled = churnunlabeled.withColumnRenamed(\"churn_risk_score\", \"actual_churn_risk_score\")\n",
    "        churnunlabeled = churnunlabeled.withColumn(\"predicted_churn_risk_score\", lit(None))\n",
    "    return churnlabeled, churnunlabeled, reservedFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "f0a958c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_feature_target_cols(churnDataFrame: DataFrame) -> tuple[list,str]:\n",
    "    \"\"\"\n",
    "    Separates the input DataFrame columns into features and target variable.\n",
    "    Uses all columns except the last as features, and the last column as target.\n",
    "    Args:\n",
    "        churnDataFrame: Input DataFrame containing cleaned churn data.\n",
    "    Returns:\n",
    "        featureCols: List of all feature column names.\n",
    "        targetCol: Name of the target column to predict.\n",
    "    \"\"\"\n",
    "    featureCols = churnDataFrame.columns[:-1]\n",
    "    targetCol = churnDataFrame.columns[-1]\n",
    "    print(f\"All Feature Columns: {featureCols}\")\n",
    "    print(f\"Target Column: {targetCol}\")\n",
    "    return featureCols, targetCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "e63d0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(churnDataFrame: DataFrame, featureCols: list,\n",
    "                         targetCol: str, moderateVal: float, strongVal: float) -> list:\n",
    "    \"\"\"\n",
    "    Performs correlation analysis between features and target variable.\n",
    "    Identifies features with strong, moderate and weak correlation based on threshold values.\n",
    "    Args:\n",
    "        churnDataFrame: Input DataFrame containing features and target.\n",
    "        featureCols: List of feature column names to analyze.\n",
    "        targetCol: Name of the target column.\n",
    "        moderateVal: Threshold for moderate correlation.\n",
    "        strongVal: Threshold for strong correlation.\n",
    "    Returns:\n",
    "        list: Features showing strong/moderate correlation with target.\n",
    "    \"\"\"\n",
    "    print(\"Begin correlation analysis of all features...\\n\")\n",
    "\n",
    "    corrVals = []\n",
    "    for feature in featureCols:\n",
    "        corr = churnDataFrame.stat.corr(feature, targetCol)\n",
    "        corrVals.append((feature, corr))\n",
    "\n",
    "    corrDf = spark.createDataFrame(corrVals, [\"feature\", \"pearson_correlation\"]) \\\n",
    "                  .orderBy(abs(col(\"pearson_correlation\")).desc())\n",
    "    corrDf = corrDf.withColumn(\"feature_strength\",\n",
    "         when(abs(col(\"pearson_correlation\")) > strongVal, \"Strong\")\n",
    "        .when(abs(col(\"pearson_correlation\")) > moderateVal, \"Moderate\")\n",
    "        .otherwise(\"Weak\"))\n",
    "    \n",
    "    print(\"\\nAll Correlation Scores:\")\n",
    "    corrDf.show(n=corrDf.count(), truncate=False)\n",
    "    print()\n",
    "    print(\"\\nFeatures displaying the strongest predictive signal:\")\n",
    "    filteredCorrDf = corrDf.filter(col(\"feature_strength\").isin(\"Strong\", \"Moderate\"))\n",
    "    filteredCorrDf.orderBy(abs(col(\"pearson_correlation\")).desc()).show(truncate=False)\n",
    "    strongCorrFeatures = filteredCorrDf.select(\"feature\").rdd.flatMap(lambda x: x).collect()\n",
    "    return strongCorrFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "40a457f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_assemble(churnDataframe, featureCols, \n",
    "                     trainSplit:float, testSplit:float) -> tuple[DataFrame, DataFrame, bool]:\n",
    "    \"\"\"\n",
    "    Combines features into vector format and splits data into training and test sets.\n",
    "    Creates feature vectors for XGBoost and performs train-test split as specified.\n",
    "    Args:\n",
    "        churnDataframe: Input DataFrame containing features\n",
    "        featureCols: List of feature column names to assemble\n",
    "        trainSplit: Proportion of data for training (%)\n",
    "        testSplit: Proportion of data for testing (%)\n",
    "    Returns:\n",
    "        trainDf: Training dataset with feature vectors\n",
    "        testDf: Test dataset with feature vectors\n",
    "    \"\"\"\n",
    "    print(\"Assembling features...\")\n",
    "    print(\"Combining all features into single vector...\")\n",
    "    assembler_all = VectorAssembler(inputCols = featureCols, outputCol=\"features\") \n",
    "    pipeline = Pipeline(stages=[assembler_all])\n",
    "    vectorDf = pipeline.fit(churnDataframe).transform(churnDataframe)\n",
    "    print(\"Splitting data...\")\n",
    "    print(f\"{trainSplit*100}/{testSplit*100} Test Train Split...\")\n",
    "    trainDf, testDf = vectorDf.randomSplit([trainSplit, testSplit], seed=42)\n",
    "    return trainDf, testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "2fe766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(trainDf, testDf, targetCol) -> tuple[DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Trains and evaluates a baseline XGBoost model using all available features.\n",
    "    Returns the trained model and its F1 score on the test set.\n",
    "    Args:\n",
    "        trainDf: Training DataFrame containing feature vectors\n",
    "        testDf: Test DataFrame for model evaluation\n",
    "        targetCol: Name of the target/label column\n",
    "    Returns:\n",
    "        xgbModel: Trained XGBoost model\n",
    "        baselineF1Score: F1 score achieved on test data\n",
    "    \"\"\"\n",
    "    xgbClassifier = SparkXGBClassifier(features_col=\"features\", label_col=targetCol, \n",
    "                                       prediction_col=\"prediction\", num_workers=cores)\n",
    "    xgbModel = xgbClassifier.fit(trainDf)\n",
    "    predictions = xgbModel.transform(testDf)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=targetCol,predictionCol=\"prediction\",metricName=\"f1\")\n",
    "    baseF1Score = round(evaluator.evaluate(predictions),5)\n",
    "    precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
    "    recall = evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
    "    acc = MulticlassClassificationEvaluator(labelCol=targetCol,predictionCol=\"prediction\",metricName=\"accuracy\").evaluate(predictions)\n",
    "    auc = BinaryClassificationEvaluator(labelCol=targetCol,rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\").evaluate(predictions)\n",
    "    conf_matrix = predictions.groupBy(\"prediction\", \"churn_risk_score\").count()\n",
    "\n",
    "    print(f\"Base Model F1 Score: {round(baseF1Score, 5)}\")\n",
    "    print(f\"Base Model Precision: {round(precision, 5)}\")\n",
    "    print(f\"Base Model Recall: {round(recall, 5)}\")\n",
    "    print(f\"Accuracy: {round(acc, 5)}\")\n",
    "    print(f\"ROC AUC: {round(auc, 5)}\")\n",
    "    conf_matrix.show()\n",
    "    return xgbModel, baseF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "6f22c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_information_gain(model, featureCols) -> list:\n",
    "    \"\"\"\n",
    "    Extracts and displays feature importances based on information gain from a trained XGBoost model.\n",
    "    Returns a list of features with strong or moderate importance.\n",
    "    Args:\n",
    "        model: Trained XGBoost model from SparkXGBClassifier\n",
    "        featureCols: List of original feature column names used for training\n",
    "    Returns:\n",
    "        strongGainFeatures: List of feature names with 'Strong' or 'Moderate' information gain\n",
    "    \"\"\"\n",
    "    importances = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    print(\"All Feature Importances by Information Gain:\")\n",
    "\n",
    "    featureMap = {f\"f{i}\": name for i, name in enumerate(featureCols)}\n",
    "    sortedImportances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    featureDict = {}\n",
    "    for feature, score in sortedImportances:\n",
    "        feature = featureMap.get(feature, feature)\n",
    "        featureDict[feature] = score\n",
    "    scoreList = [[featureMap.get(feat, feat), score] for feat, score in sortedImportances]\n",
    "    allFeatureGainDf = spark.createDataFrame(scoreList, [\"feature\", \"gain\"])\n",
    "    allFeatureGainDf = allFeatureGainDf.withColumn(\"gain_strength\",\n",
    "         when(abs(col(\"gain\")) > 30, \"Strong\")\n",
    "        .when(abs(col(\"gain\")) > 10, \"Moderate\")\n",
    "        .otherwise(\"Weak\"))\n",
    "    allFeatureGainDf.show(n=allFeatureGainDf.count(), truncate=False)\n",
    "    print(\"Features with stronger information gain scores...\")\n",
    "    strongGainDf = allFeatureGainDf.filter(col(\"gain_strength\").isin(\"Strong\", \"Moderate\"))\n",
    "    strongGainDf.orderBy(abs(col(\"gain_strength\")).desc()).show(truncate=False)\n",
    "    strongGainFeatures = strongGainDf.select(\"feature\").rdd.flatMap(lambda x: x).collect()\n",
    "    return strongGainFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "82037007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strong_features(corrFeatures: list, gainFeatures: list) -> list:\n",
    "    \"\"\"\n",
    "    Combines features selected via correlation and information gain into a unified list of strong features.\n",
    "    Args:\n",
    "        corrFeatures: List of features selected based on correlation analysis\n",
    "        gainFeatures: List of features selected based on information gain from the model\n",
    "    Returns:\n",
    "        strongFeatures: Combined list of unique features deemed strong by either method\n",
    "    \"\"\"\n",
    "    strongFeatures = list(set(corrFeatures + gainFeatures))\n",
    "    print(f\"Strong feature list: {strongFeatures}\")\n",
    "    return strongFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "e9cf5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(trainDf, testDf, featureCols, \n",
    "                           targetCol, k=2)-> tuple[GBTClassificationModel, float]:\n",
    "    \"\"\"\n",
    "    Performs k-fold cross-validation using a Gradient-Boosted Tree (GBT) model and evaluates performance on test data.\n",
    "    Args:\n",
    "        trainDf: Training DataFrame containing feature columns and target\n",
    "        testDf: Test DataFrame for final model evaluation\n",
    "        featureCols: List of selected feature column names\n",
    "        TargetCol: Name of the target/label column\n",
    "        modelType: Type of model to train (currently supports \"GBT\" only)\n",
    "        k: Number of folds for cross-validation\n",
    "    Returns:\n",
    "        bestModel: Best-performing GBT model from cross-validation\n",
    "        optimisedF1Score: F1 score of the best model evaluated on the test set\n",
    "    \"\"\"\n",
    "    print(f\"Running {k}-fold CV on training data\")\n",
    "    assembler = VectorAssembler(inputCols= featureCols, outputCol=\"strongFeatures\")\n",
    "    train = assembler.transform(trainDf).select(\"strongFeatures\", targetCol)\n",
    "    test = assembler.transform(testDf).select(\"strongFeatures\", targetCol)\n",
    "\n",
    "    model = SparkXGBClassifier(label_col=targetCol, \n",
    "                               features_col=\"strongFeatures\",\n",
    "                               prediction_col=\"prediction\",\n",
    "                               num_workers=cores)\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(model.getParam(\"max_depth\"), [3, 5]) \\\n",
    "        .addGrid(model.getParam(\"learning_rate\"), [0.05, 0.1]) \\\n",
    "        .addGrid(model.getParam(\"subsample\"), [0.8, 1.0]) \\\n",
    "        .build()\n",
    "\n",
    "    # Evaluator\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=targetCol,\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"f1\")\n",
    "\n",
    "    # CrossValidator\n",
    "    cv = CrossValidator(\n",
    "        estimator=model,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=k,\n",
    "        parallelism=cores)\n",
    "\n",
    "    cvModel = cv.fit(train)\n",
    "    predictions = cvModel.transform(test)\n",
    "    print(predictions)\n",
    "    optimisedF1Score = round(evaluator.evaluate(predictions),5)\n",
    "    precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
    "    recall = evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
    "    \n",
    "    acc = MulticlassClassificationEvaluator(labelCol=targetCol,predictionCol=\"prediction\",metricName=\"accuracy\").evaluate(predictions)\n",
    "    auc = BinaryClassificationEvaluator(labelCol=targetCol,rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\").evaluate(predictions)\n",
    "    conf_matrix = predictions.groupBy(\"prediction\", \"churn_risk_score\").count()\n",
    "\n",
    "    print(f\"Optimised Model F1 Score: {round(optimisedF1Score, 5)}\")\n",
    "    print(f\"Optimised Precision: {round(precision, 5)}\")\n",
    "    print(f\"Optimised Recall: {round(recall, 5)}\\n\")\n",
    "    print(f\"Accuracy: {round(acc, 5)}\")\n",
    "    print(f\"ROC AUC: {round(auc, 5)}\")\n",
    "    conf_matrix.show()\n",
    "    \n",
    "    return cvModel.bestModel, optimisedF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "fa7f4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(baselineF1, optimisedF1, baseModel, \n",
    "                      optimisedModel, strongFeatures, allFeatures) -> tuple[ClassificationModel, str, list]:\n",
    "    \"\"\"\n",
    "    Compares baseline and optimised model F1 scores and selects the better-performing model.\n",
    "    Args:\n",
    "        baselineF1: F1 score of the baseline model\n",
    "        optimisedF1: F1 score of the optimised model\n",
    "        baseModel: Trained baseline model\n",
    "        optimisedModel: Trained optimised model from cross-validation\n",
    "        strongFeatures: List of features used in the optimised model\n",
    "        allFeatures: List of features used in the baseline model\n",
    "    Returns:\n",
    "        model: The selected model (either baseline or optimised)\n",
    "        modelType: String indicating which model was selected (\"base\" or \"optimised\")\n",
    "        features: List of features associated with the selected model\n",
    "    \"\"\"\n",
    "    print(f\"Base model F1 Score: {baselineF1}\")\n",
    "    print(f\"Optimised model F1 Score: {optimisedF1}\")\n",
    "    if optimisedF1 > baselineF1:\n",
    "        model = optimisedModel\n",
    "        modelType = \"optimised\"\n",
    "        features = strongFeatures\n",
    "        print(f\"Optimised model selected...\")\n",
    "    else:\n",
    "        model = baseModel\n",
    "        modelType = \"base\"\n",
    "        features = allFeatures\n",
    "        print(f\"Base model selected...\")\n",
    "    return model, modelType, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "40d0abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn_score(modelType, model, \n",
    "                        churnDataUnlabelled: DataFrame, features, reservedFlag) -> None:\n",
    "    \"\"\"\n",
    "    Applies the selected model to unlabeled churn data and displays predictions along with accuracy if labels exist.\n",
    "    Args:\n",
    "        modelType: Type of model used (\"base\" or \"optimised\")\n",
    "        model: Trained classification model\n",
    "        churnDataUnlabelled: DataFrame containing data to predict churn scores on\n",
    "        features: List of feature columns to be used for prediction\n",
    "        reservedFlag: Reserved argument (not currently used)\n",
    "    Returns:\n",
    "        None. Prints prediction results and accuracy (if actual labels are available).\n",
    "    \"\"\"\n",
    "    if modelType == \"optimised\":\n",
    "        feature_vector_col = \"strongFeatures\"\n",
    "        selectedFeatures = ['actual_churn_risk_score'] + features\n",
    "    else:\n",
    "        feature_vector_col = \"features\"\n",
    "        selectedFeatures = ['actual_churn_risk_score'] + features\n",
    "\n",
    "    churnDataUnlabelled = churnDataUnlabelled.select(*[feature for feature in selectedFeatures if feature in churnDataUnlabelled.columns])\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=features, outputCol=feature_vector_col)\n",
    "    churnunlabeledPredict = assembler.transform(churnDataUnlabelled)\n",
    "    predictions = model.transform(churnunlabeledPredict)\n",
    "\n",
    "    predictions = predictions.withColumnRenamed(\"prediction\", \"predicted_churn_risk_score\")\n",
    "    \n",
    "    # Determine which label column to use\n",
    "    if \"actual_churn_risk_score\" in predictions.columns:\n",
    "        label_col = \"actual_churn_risk_score\"\n",
    "    elif \"churn_risk_score\" in predictions.columns:\n",
    "        label_col = \"churn_risk_score\"\n",
    "\n",
    "    if label_col:\n",
    "        selected_df = predictions.select(label_col, \"predicted_churn_risk_score\")\n",
    "        print(f\"\\n----- Prediction Results ({modelType} model using '{label_col}') -----\")\n",
    "        selected_df = selected_df.withColumn(\"predicted_churn_risk_score\", selected_df[\"predicted_churn_risk_score\"].cast(IntegerType()))\n",
    "        selected_df.show(truncate=False)\n",
    "\n",
    "        correct = predictions.filter(col(label_col) == col(\"predicted_churn_risk_score\")).count()\n",
    "        total = predictions.count()\n",
    "        accuracy = correct / total if total else 0\n",
    "        print(f\"Prediction Accuracy: {accuracy:.2%} ({correct}/{total})\")\n",
    "    else:\n",
    "        print(\"\\nNo label column found ('actual_churn_risk_score' or 'churn_risk_score') in data.\")\n",
    "        predictions.select(\"predicted_churn_risk_score\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "f6d4bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_ml_pipeline() -> None:\n",
    "    \"\"\"\n",
    "    Orchestrates the entire machine learning pipeline for churn prediction.\n",
    "    This function performs the following steps:\n",
    "        1. Combines and loads cleaned churn data.\n",
    "        2. Splits the dataset into labeled and unlabeled data.\n",
    "        3. Trains a baseline XGBoost model using all features.\n",
    "        4. Evaluates feature importance via correlation and information gain.\n",
    "        5. Trains an optimised model using top-ranked features and cross-validation.\n",
    "        6. Compares baseline and optimised models and selects the better one.\n",
    "        7. Applies the best model to make predictions on unseen (unlabeled) data.\n",
    "        8. Logs pipeline execution time.\n",
    "    Returns:\n",
    "        None. All results are printed to the console during execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    print(\"Spark session created: ChurnXGBoost \")\n",
    "    print()\n",
    "\n",
    "    randomId = uuid.uuid4()\n",
    "    stringID = str(randomId)\n",
    "    print(f\"Executing Machine Learning Pipeline...\")\n",
    "    print() \n",
    "    print(f\"Run ID: {stringID}\")\n",
    "    print()\n",
    "\n",
    "    print(\"***** DATA PREPARATION *****\", end=\"\\n\")\n",
    "    print()\n",
    "    \n",
    "    print(\"===== Combine Cleaned Files and Load Data =====\", end=\"\\n\")\n",
    "    churnData = concatenate_clean_churn_files()\n",
    "\n",
    "    print(\"===== Cleaned Churn Metadata =====\", end=\"\\n\")\n",
    "    get_churn_metadata(churnData)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Split Dataframe by labels =====\", end=\"\\n\")\n",
    "    churnDataLabelled, churnDataUnlabelled, reservedFlag = split_dataframe_by_label(churnData)\n",
    "    print()\n",
    "\n",
    "    print(\"***** TRAIN AND SCORE BASELINE MODEL *****\", end=\"\\n\")\n",
    "    print()\n",
    "\n",
    "    print(\"===== Baseline Model: Separate Feature and Target Column/s =====\", end=\"\\n\")\n",
    "    allFeatures, targetCol = separate_feature_target_cols(churnDataLabelled)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Baseline Model: Correlation Analysis =====\", end=\"\\n\")\n",
    "    strongCorrFeatures = correlation_analysis(churnDataLabelled, allFeatures, targetCol, 0.2, 0.4)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Baseline Model: Assemble Features =====\", end=\"\\n\")\n",
    "    trainSetDf, testSetDf = feature_assemble(churnDataLabelled, allFeatures, trainSplit=0.8, testSplit=0.2)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Baseline Model: Create and Score =====\",end=\"\\n\")\n",
    "    baseModel, baselineF1Score = baseline_model(trainSetDf, testSetDf, targetCol)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Baseline Model: Feature Information Gain =====\",end=\"\\n\")\n",
    "    strongGainFeatures = feature_information_gain(baseModel, allFeatures)\n",
    "    print()\n",
    "\n",
    "    print(\"***** TRAIN AND SCORE OPTIMISED MODEL *****\",end=\"\\n\")\n",
    "    print()\n",
    "\n",
    "    print(\"===== Optimised Model: Strongest Features =====\",end=\"\\n\")\n",
    "    strongFeatures = get_strong_features(strongCorrFeatures, strongGainFeatures)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Optimised Model: K-Fold Cross Validation =====\",end=\"\\n\")\n",
    "    optimisedModel, optimisedF1Score = kfold_cross_validation(trainSetDf, testSetDf, strongFeatures, targetCol)\n",
    "    print()\n",
    "\n",
    "    print(\"***** SELECT BEST MODEL AND PREDICT UNSEEN DATA *****\",end=\"\\n\")\n",
    "    print()\n",
    "\n",
    "    print(\"===== Select Best Model =====\",end=\"\\n\")\n",
    "    bestModel, modelType, features = select_best_model(baselineF1Score, optimisedF1Score,\n",
    "                                             baseModel, optimisedModel, strongFeatures, allFeatures)\n",
    "    print()\n",
    "\n",
    "    print(\"===== Apply Model to Unseen Data =====\",end=\"\\n\")\n",
    "    predict_churn_score(modelType, bestModel, churnDataUnlabelled, features, reservedFlag)\n",
    "    \n",
    "    endTime = time.time()\n",
    "    pipelineRunTime = endTime - startTime\n",
    "    print(f\"Machine learning pipeline complete. Run time: {timedelta(seconds=int(pipelineRunTime))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b9b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created: ChurnXGBoost \n",
      "\n",
      "Executing Machine Learning Pipeline...\n",
      "\n",
      "Run ID: bbfcf275-36d2-4c50-b086-a498509fa379\n",
      "\n",
      "***** DATA PREPARATION *****\n",
      "\n",
      "===== Combine Cleaned Files and Load Data =====\n",
      "All available cleaned churn csv files: ['churn_clean.csv']\n",
      "===== Cleaned Churn Metadata =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   age                           20000 non-null  int32  \n",
      " 1   gender                        20000 non-null  int32  \n",
      " 2   region_category               20000 non-null  int32  \n",
      " 3   membership_category           20000 non-null  int32  \n",
      " 4   joined_through_referral       20000 non-null  int32  \n",
      " 5   preferred_offer_types         20000 non-null  int32  \n",
      " 6   medium_of_operation           20000 non-null  int32  \n",
      " 7   internet_option               20000 non-null  int32  \n",
      " 8   days_since_last_login         20000 non-null  int32  \n",
      " 9   avg_time_spent                20000 non-null  float64\n",
      " 10  avg_transaction_value         20000 non-null  float64\n",
      " 11  avg_frequency_login_days      20000 non-null  int32  \n",
      " 12  points_in_wallet              20000 non-null  float64\n",
      " 13  used_special_discount         20000 non-null  int32  \n",
      " 14  offer_application_preference  20000 non-null  int32  \n",
      " 15  past_complaint                20000 non-null  int32  \n",
      " 16  complaint_status              20000 non-null  int32  \n",
      " 17  feedback                      20000 non-null  int32  \n",
      " 18  join_year                     20000 non-null  int32  \n",
      " 19  join_month                    20000 non-null  int32  \n",
      " 20  join_day                      20000 non-null  int32  \n",
      " 21  last_visit_hour               20000 non-null  int32  \n",
      " 22  last_visit_min                20000 non-null  int32  \n",
      " 23  last_visit_sec                20000 non-null  int32  \n",
      " 24  churn_risk_score              20000 non-null  int32  \n",
      "dtypes: float64(3), int32(22)\n",
      "memory usage: 2.1 MB\n",
      "\n",
      "===== Split Dataframe by labels =====\n",
      "no empty churn_risk_score rows...\n",
      "Reserving 1% of labeled data for demo predictions...\n",
      "Reserve dataframe with 208 rows\n",
      "\n",
      "***** TRAIN AND SCORE BASELINE MODEL *****\n",
      "\n",
      "===== Baseline Model: Separate Feature and Target Column/s =====\n",
      "All Feature Columns: ['age', 'gender', 'region_category', 'membership_category', 'joined_through_referral', 'preferred_offer_types', 'medium_of_operation', 'internet_option', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet', 'used_special_discount', 'offer_application_preference', 'past_complaint', 'complaint_status', 'feedback', 'join_year', 'join_month', 'join_day', 'last_visit_hour', 'last_visit_min', 'last_visit_sec']\n",
      "Target Column: churn_risk_score\n",
      "\n",
      "===== Baseline Model: Correlation Analysis =====\n",
      "Begin correlation analysis of all features...\n",
      "\n",
      "\n",
      "All Correlation Scores:\n",
      "+----------------------------+---------------------+----------------+\n",
      "|feature                     |pearson_correlation  |feature_strength|\n",
      "+----------------------------+---------------------+----------------+\n",
      "|membership_category         |-0.4644145540752387  |Strong          |\n",
      "|avg_transaction_value       |-0.21670086929826687 |Moderate        |\n",
      "|points_in_wallet            |-0.2077226314261469  |Moderate        |\n",
      "|avg_frequency_login_days    |0.14246476558304483  |Weak            |\n",
      "|feedback                    |-0.12729664500324794 |Weak            |\n",
      "|preferred_offer_types       |0.04277998339325452  |Weak            |\n",
      "|joined_through_referral     |0.030535720934640978 |Weak            |\n",
      "|days_since_last_login       |0.023087402336053473 |Weak            |\n",
      "|past_complaint              |0.019461328637430487 |Weak            |\n",
      "|used_special_discount       |-0.01744458886984828 |Weak            |\n",
      "|offer_application_preference|-0.014619386210010634|Weak            |\n",
      "|avg_time_spent              |-0.01029762218541746 |Weak            |\n",
      "|join_day                    |0.009988916581946618 |Weak            |\n",
      "|medium_of_operation         |0.008906670793867269 |Weak            |\n",
      "|age                         |0.00868741703381818  |Weak            |\n",
      "|join_month                  |0.00855686069677683  |Weak            |\n",
      "|complaint_status            |0.008112710188245081 |Weak            |\n",
      "|region_category             |-0.007180234415781032|Weak            |\n",
      "|internet_option             |-0.005807078282886454|Weak            |\n",
      "|last_visit_sec              |0.005800782990621628 |Weak            |\n",
      "|gender                      |-0.005476132649570174|Weak            |\n",
      "|last_visit_hour             |-0.005194617790894275|Weak            |\n",
      "|last_visit_min              |0.003286625495654285 |Weak            |\n",
      "|join_year                   |0.003178843031535454 |Weak            |\n",
      "+----------------------------+---------------------+----------------+\n",
      "\n",
      "\n",
      "\n",
      "Features displaying the strongest predictive signal:\n",
      "+---------------------+--------------------+----------------+\n",
      "|feature              |pearson_correlation |feature_strength|\n",
      "+---------------------+--------------------+----------------+\n",
      "|membership_category  |-0.4644145540752387 |Strong          |\n",
      "|avg_transaction_value|-0.21670086929826687|Moderate        |\n",
      "|points_in_wallet     |-0.2077226314261469 |Moderate        |\n",
      "+---------------------+--------------------+----------------+\n",
      "\n",
      "\n",
      "===== Baseline Model: Assemble Features =====\n",
      "Assembling features...\n",
      "Combining all features into single vector...\n",
      "Splitting data...\n",
      "80.0/20.0 Test Train Split...\n",
      "\n",
      "===== Baseline Model: Create and Score =====\n",
      "Base Model F1 Score: 0.93265\n",
      "Base Model Precision: 0.93415\n",
      "Base Model Recall: 0.93282\n",
      "Accuracy: 0.93282\n",
      "ROC AUC: 0.9772\n",
      "+----------+----------------+-----+\n",
      "|prediction|churn_risk_score|count|\n",
      "+----------+----------------+-----+\n",
      "|       0.0|               1|   73|\n",
      "|       0.0|               0| 1654|\n",
      "|       1.0|               0|  189|\n",
      "|       1.0|               1| 1984|\n",
      "+----------+----------------+-----+\n",
      "\n",
      "\n",
      "===== Baseline Model: Feature Information Gain =====\n",
      "All Feature Importances by Information Gain:\n",
      "+----------------------------+------------------+-------------+\n",
      "|feature                     |gain              |gain_strength|\n",
      "+----------------------------+------------------+-------------+\n",
      "|points_in_wallet            |45.88572311401367 |Strong       |\n",
      "|membership_category         |43.550758361816406|Strong       |\n",
      "|feedback                    |8.441245079040527 |Weak         |\n",
      "|avg_transaction_value       |3.979185104370117 |Weak         |\n",
      "|offer_application_preference|2.3898351192474365|Weak         |\n",
      "|complaint_status            |2.2818808555603027|Weak         |\n",
      "|age                         |2.1708574295043945|Weak         |\n",
      "|internet_option             |2.113652229309082 |Weak         |\n",
      "|medium_of_operation         |2.0954749584198   |Weak         |\n",
      "|last_visit_hour             |2.068673610687256 |Weak         |\n",
      "|last_visit_min              |2.0450172424316406|Weak         |\n",
      "|gender                      |1.99639093875885  |Weak         |\n",
      "|avg_frequency_login_days    |1.9728995561599731|Weak         |\n",
      "|join_month                  |1.9727933406829834|Weak         |\n",
      "|join_year                   |1.958180546760559 |Weak         |\n",
      "|join_day                    |1.9554499387741089|Weak         |\n",
      "|avg_time_spent              |1.9470627307891846|Weak         |\n",
      "|days_since_last_login       |1.9202637672424316|Weak         |\n",
      "|region_category             |1.9194161891937256|Weak         |\n",
      "|used_special_discount       |1.9040329456329346|Weak         |\n",
      "|last_visit_sec              |1.815616488456726 |Weak         |\n",
      "|past_complaint              |1.7969512939453125|Weak         |\n",
      "|preferred_offer_types       |1.7362953424453735|Weak         |\n",
      "|joined_through_referral     |1.5224227905273438|Weak         |\n",
      "+----------------------------+------------------+-------------+\n",
      "\n",
      "Features with stronger information gain scores...\n",
      "+-------------------+------------------+-------------+\n",
      "|feature            |gain              |gain_strength|\n",
      "+-------------------+------------------+-------------+\n",
      "|points_in_wallet   |45.88572311401367 |Strong       |\n",
      "|membership_category|43.550758361816406|Strong       |\n",
      "+-------------------+------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** TRAIN AND SCORE OPTIMISED MODEL *****\n",
      "\n",
      "===== Optimised Model: Strongest Features =====\n",
      "Strong feature list: ['membership_category', 'points_in_wallet', 'avg_transaction_value']\n",
      "\n",
      "===== Optimised Model: K-Fold Cross Validation =====\n",
      "Running 2-fold CV on training data\n"
     ]
    }
   ],
   "source": [
    "execute_ml_pipeline() # Execute pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
